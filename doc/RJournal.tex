\documentclass[a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{RJournal}
\usepackage{amsmath,amssymb,array}
\usepackage{booktabs}



\begin{document}
%% do not edit, for illustration only
\sectionhead{Contributed research article}
\volume{XX}
\volnumber{YY}
\year{20ZZ}
\month{AAAA}
\begin{article}
\title{TeXCheckR}
\author{Hugh Parsonage}

\maketitle

\abstract{
Checking a report for typos is a task for computers. 
Yet tools used for proof-reading are often misused or not appropriate for the task.
The package TeXCheckR is designed to provide flexible rules, enforced rigidly, for \LaTeX{} documents.
}



\section{Introduction}
Everyone makes typos.
And everyone notices them.
Although some tasks in the domain of proof-reading are only possible or still most efficiently done by humans, many tasks would be far better delegated to computers.

Spell-checkers are interesting in this respect. 
A few subtleties aside, there is nothing difficult in a writing a spell-checker: collect all the words in a document, find the ones that are not matched with a given dictionary, and return those errors. 
However, I claim that the presence of typos in published works shows that current applications are failing this basic task.
In practice there are two difficulties than typical spell-checkers do poorly: 
(1) the ability to add words to the dictionary of the \emph{document}, and
(2) the authority to enforce spell-checking on authors.
Put another way, spell-checkers are too independent of the document being written, do not provide enough flexibility to authors, and do not have enough authority over authors.

There are other typing errors that occur when producing \LaTeX{} documents in particular, such as accidental whitespace, as well as rules concerning style -- for example, requiring all figures and tables are referenced in the body text. 

\section{hunspell}
The hunspell package does the bulk of the work in checking the spelling.
However, hunspell cannot overcome the two difficulties mentioned in the introduction.
Firstly, hunspell's ability to add words to the dictionary is endowed by the user, rather than the document.
This is, admittedly, a small 

Secondly, hunspell does not provide authors with the ability to add words to its dictionaries on-the-fly or in documents themselves. 
In large documents, or documents with a technical focus, this leads to numerous false positives, which, in practice are typically ignored, which defeat its purpose.

Lastly, hunspell may provide false negatives: in certain cases, an author may want to forbid certain spellings from appearing to enforce a style.
Both ``authorise'' and ``authorize'' are equally valid in Australian and British English, but an author should be able to pick one and flag the other as a spelling error. 

\subsection{Acronyms and initalisms}
TeXCheckR parses the document for acronyms, so that authors do not have to add these to the dictionary.

\section{Bibliography parsing}
The package RefManageR provides a feature-rich interface with \texttt{.bib} files with input provide via the bibtex package.
TeXCheckR takes a different approach: instead of dealing with the tasks of input, cleaning, parsing, and validating in one function, it farms these out to discrete exported functions.
In particular, the main parsing function, \verb=fread_bib= is quite fussy about the input file; for example,
it requires that every field type has a trailing a comma, even when this is not required by \verb=biber=.

Being fussy about the input has the obvious disadvantage that not every valid \texttt{.bib} file, let alone every invalid \texttt{.bib} file, will be successfully read.
To overcome this disadvantage, TeXCheckR ships with a function \verb=lint_bib= which, more or less, converts a bib file into one that \verb=fread_bib= will accept. 
It performs two main tasks: first, it collapses each field-values spread over multiple lines into a single line; and, second, it ensures the \verb!=! sign occurs at an constant column in the text file (for cosmetic reasons).

The big advantage is speed. 
TeXCheckR is much faster than RefManageR at reading bib files.

\begin{table}
\begin{tabular}{lrrrrrrrl}
  \toprule
  & \multicolumn{7}{c}{milliseconds} & \\
  \cmidrule{2-7}
 expr & min & lq & mean & median & uq & max & neval & cld \\ 
  \midrule
\texttt{fread\_bib} & 183.93 & 216.30 & 252.40 & 225.55 & 298.60 & 339.88 & 10 & a  \\ 
\texttt{ReadBib} & 8286.72 & 8499.61 & 8576.95 & 8528.89 & 8626.30 & 9189.89 & 10 &  b \\ 
   \bottomrule
\end{tabular}
{\footnotesize Source: 10 iterations via \texttt{microbenchmark}.}
\end{table}

% \begin{example}

% \end{example}
\address{Author One\\
  Affiliation\\
  Address\\
  Country\\
  (ORCiD if desired)\\
  \email{author1@work}}
\end{article}
\end{document}
